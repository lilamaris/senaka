OPENAI_BASE_URL=http://example/v1
OPENAI_API_KEY=lm-studio
OPENAI_MODEL=local-model
WORKER_OPENAI_MODEL=local-model-worker
SYSTEM_PROMPT=You are a pragmatic local host assistant.
SESSION_DIR=./data/sessions
MODEL_PROFILES_PATH=./config/model-profiles.json
CHAT_AGENT_ID=default
# CHAT_MODEL_ID=main-default
TOOL_SANDBOX_MODE=local
TOOL_SHELL_PATH=/bin/zsh
DOCKER_SHELL_PATH=/bin/sh
TOOL_TIMEOUT_MS=20000
TOOL_MAX_BUFFER_BYTES=1048576
TOOL_MAX_PIPES=2
DOCKER_SANDBOX_IMAGE=senaka-sandbox:bookworm
DOCKER_REQUIRED_TOOLS=sh,ls,cat,echo,grep,sed,awk,find,head,tail,wc,pwd,rg,jq,git,python3
# Optional: one-time init command per workspace group (marker: /workspace/.senaka/init.done)
# DOCKER_WORKSPACE_INIT_COMMAND=mkdir -p tmp
DOCKER_WORKSPACE_ROOT=./data/workspaces
DOCKER_CONTAINER_PREFIX=senaka-ws
DOCKER_NETWORK=none
DOCKER_MEMORY=512m
DOCKER_CPUS=1.0
DOCKER_PIDS_LIMIT=256
WORKER_ENABLE_THINKING=false
WORKER_THINKING_PREFILL=<think></think>
WORKER_MAX_RESPONSE_TOKENS=256
WORKER_ACTION_MAX_RETRIES=6
DEBUG_LLM_REQUESTS=false
MAIN_DECISION_ENABLE_THINKING=false
MAIN_DECISION_THINKING_PREFILL=<think></think>
